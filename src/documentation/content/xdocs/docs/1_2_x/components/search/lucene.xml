<?xml version="1.0" encoding="UTF-8"?>
<!--
  Copyright 1999-2004 The Apache Software Foundation

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->

<!-- $Id: lucene.xml 55543 2004-10-26 00:14:59Z gregor $ -->

<!DOCTYPE document PUBLIC "-//APACHE//DTD Documentation V2.0//EN" "http://forrest.apache.org/dtd/document-v20.dtd">

<document> 

<header> 
    <title>Lucene</title>
     
     
     
</header> 
<body> 

<section>
<title>Overview</title>
<p>There are two URL for the search screen relative to your publication: 
    <code>search-live/lucene</code> to search the live area, <code>search-authoring/lucene</code> to 
    search the authoring area of your publication.</p>
<p>If you want to customize the layout of  the search screen for your publication, 
    place a stylesheet at <code>lenya/xslt/search/search-and-results.xsl</code>
     relative to your publication root.</p>
<p>Lucene indices are stored within the <code>work/search/index/$AREA/index</code> directory of your 
    publication. The <code>work/search/htdocs_dump/$AREA</code> directory holds content from crawling (see below).</p>

<p>The search pipelines are defined within <code>global-sitemap.xmap</code> and <code>lucene.xmap</code></p>
</section>

<section>
<title>Crawling a website</title>
<p>
Crawl a website by running
</p>
<source>
<![CDATA[
ant -f build/lenya/webapp/lenya/bin/crawl_and_index.xml -Dcrawler.xconf=build/lenya/webapp/lenya/pubs/default/config/search/crawler-live.xconf crawl
]]>
</source>
<p>
Note that there is a search.properties file in build/lenya/webapp/lenya/bin that you may have to change.
crawler.xconf needs to have the following elements:
</p>
<source>
<![CDATA[
<crawler>
  <user-agent>lenya</user-agent>

  <base-url href="http://lenya.apache.org/index.html"/>
  <scope-url href="http://lenya.apache.org/"/>

  <uri-list src="work/search/lucene/uris.txt"/>
  <htdocs-dump-dir src="work/search/lucene/htdocs_dump/lenya.apache.org"/>

  <!-- <robots src="robots.txt" domain="lenya.apache.org"/> -->
</crawler>
]]>
</source>
<ul>
    <li>user-agent is the HTTP user agent that will be used for the crawler</li>
    <li>base-url is the start URL for the crawler</li>
    <li>scope-url limits the scope of the crawl to that site, or subdirectory</li>
    <li>uri-list is a reference to a file that will contain all URLs found during the crawl</li>
    <li>htdocs-dump-dir specifies the directory that will contain the crawled site</li>
    <li>robots specifies an (optional) robots file that follows the <a href="http://www.robotstxt.org/wc/norobots.html">Robot Exclusion Standard</a></li>
</ul>
<p>
If you want to fine-tune the crawling (and do not have access to the remote server to put a robots.txt there), then
you can specify exlusions in a local robots.txt file:
</p>
<source>
<![CDATA[
# lenya.apache.org

User-agent: *
Disallow: /there_seems_to_be_a_bug_within_websphinx_Robot_Exclusion.html

#Disallow:

User-agent: lenya
Disallow: /do/not/crawl/this/page.html
]]>
</source>
</section>

<section>
<title>Creating an index from the command line</title>
<source>
<![CDATA[
ant -f build/lenya/webapp/lenya/bin/crawl_and_index.xml -Dlucene.xconf=build/lenya/webapp/lenya/pubs/default/config/search/lucene-live.xconf index
]]>
</source>
<p>
Note that there is a search.properties file in build/lenya/webapp/lenya/bin that you may have to change.
lucene-live.xconf has the following elements
</p>
<source>
<![CDATA[
<lucene>
  <update-index type="new"/>
  <!--
  <update-index type="incremental"/>
  -->

  <index-dir src="../../work/search/lucene/index/index"/>
    <htdocs-dump-dir src="../../work/search/lucene/htdocs_dump"/>

    <indexer class="org.apache.lenya.lucene.index.DefaultIndexer"/>
</lucene>
]]>
</source>
</section>

<section>
<title>Indexing XML documents</title>

<p>
In order to index XML documents one needs to configure the <code>org.apache.lenya.lucene.index.ConfigurableIndexer</code> (see above).
</p>

<p>
With namespaces:
</p>
<source>
<![CDATA[
<?xml version="1.0"?>

<luc:document xmlns:luc="http://apache.org/cocoon/lenya/lucene/1.0">
  <luc:field name="currwfstate" type="Text" xpath="/wf:history/wf:version[last()]/@state">
    <namespace prefix="wf">http://apache.org/cocoon/lenya/workflow/1.0</namespace>
  </luc:field>
</luc:document>
]]>
</source>

<p>
Concatenating element values and setting default values in case element value doesn't exist:
</p>
<source>
<![CDATA[
<?xml version="1.0"?>

<luc:document xmlns:luc="http://apache.org/cocoon/lenya/lucene/1.0">
  <luc:field name="title" type="Text" xpath="/article/head/title"/>
  <luc:field name="subtitle" type="Text" xpath="/article/head/subtitle"/>
  <luc:field name="lead" type="UnStored" xpath="/article/head/abstract"/>
  <luc:field name="contents" type="UnStored" xpath="/"/>
  <luc:field name="author" type="UnStored"/>
    <namespace prefix="lenya">http://apache.org/cocoon/lenya/page-envelope/1.0</namespace>
    <namespace prefix="dc">http://purl.org/dc/elements/1.1/</namespace>
    <xpath>/*/lenya:meta/dc:contributor</xpath>
  </luc:field>
  <luc:field name="date" type="Text">
    <namespace prefix="lenya">http://apache.org/cocoon/lenya/page-envelope/1.0</namespace>
    <xpath default="1969">/*/lenya:meta/year</xpath><text>.</text><xpath default="02">/*/lenya:meta/month</xpath><text>.</text><xpath default="16">/*/lenya:meta/day</xpath>
  </luc:field>
</luc:document>
]]>
</source>
</section>

<section>
<title>Extract text from a PDF document</title>
<source>
<![CDATA[
ant -f build/lenya/webapp/lenya/bin/crawl_and_index.xml -Dhtdocs.dump.dir=build/lenya/webapp/lenya/pubs/default/work/search/lucene/htdocs_dump xpdf
]]>
</source>
<p>
Also see the targets <code>pdfbox</code> and <code>pdfadobe</code>.
</p>
</section>

</body>
</document>
